{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='dimgrey'> Kafka : Intro </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='grey'> What's Apache Kafka </font>\n",
    "<font color='grey'>\n",
    "It's an event streaming platform. There is a kafka producer at one end creating or streaming events into the Kafka server and at another end there is a kafka consumer consuming or processing it. It's very flexible so you can have as many producers and consumers as the use case insists. Consumer can also process the data and start producing events back to kafka server.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='grey'> Producers are also called Publishers and consumers Subscribers. RabbitMQ is a messaging broker which also has a pub/sub model and there are also some key differences.</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='grey'> So what's else different: Storage </font>\n",
    "<font color='grey'> Traditional data bases store states or instances of an atomic object as a row in a table conforming with the normalization guidelines. Kafka, produces and stores events data and let it be consumed. \n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
